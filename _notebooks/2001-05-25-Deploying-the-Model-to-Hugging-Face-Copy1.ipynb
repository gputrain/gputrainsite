{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead7e443",
   "metadata": {},
   "source": [
    "# 1 Deploying a Fast AI model to Hugging Face\n",
    "> Steps to get the hugging face gradio application to work\n",
    "\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [sound, hugging face, fastai]\n",
    "- image: images/melspectrogram.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e7038f",
   "metadata": {},
   "source": [
    "## Know before getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdee5fa",
   "metadata": {},
   "source": [
    "This notebook code is the same used to create my app.py file you can find in [UrbanSounds8k spaces repo](https://huggingface.co/spaces/gputrain/UrbanSounds8K/blob/main/app.py).\n",
    "\n",
    "Creating a space is simple and intuitive at Hugging Face. You will need a \"Create a new space\" and \"Create a new model repository\" at huggingfaces. You will find the interface to create a new model repository (repo) in your profile settings. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c86fc",
   "metadata": {},
   "source": [
    "![](images/createmodel.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c67f7fc",
   "metadata": {},
   "source": [
    "If you upload your model artifacts into your spaces repository, you will run into 404 or 403 series errors. Once you create a model repo, the installation steps of Hugging Face will have an install [git lfs](https://git-lfs.github.com/) in the set of instructions specific to the location you clone this empty repo. \n",
    "\n",
    "\n",
    "If you upload your model artifacts into your spaces repository, you will run into 404 or 403 series errors. Once you create a model repo, the installation steps of Hugging Face will have an install git lfs in the set of instructions specific to the location you clone this empty repo.  \n",
    "\n",
    "Add in that repo before copying your model the *.pkl file from the earlier step; ensure you track pkl files as a type of file managed by Git LFS\n",
    "\n",
    "git lfs track \"*.pkl\"\n",
    "\n",
    "\n",
    "> Tip: Note what is my [spaces repo](https://huggingface.co/spaces/gputrain/UrbanSounds8K/tree/main) and what is in my [model repo](https://huggingface.co/gputrain/UrbanSound8K-model/tree/main)\n",
    "\n",
    "\n",
    "If you miss this step you will run into 403 errors as you execute this line:\n",
    "\n",
    "model_file = hf_hub_download(\"gputrain/UrbanSound8K-model\", \"model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123961d9",
   "metadata": {},
   "source": [
    "Back to spaces repo, for which I have specific requirements.txt to be able to load librosa modules to get my inference function to work. In my example, I also needed to get my labeller function to get my model to work. This [requirements.txt](https://huggingface.co/spaces/gputrain/UrbanSounds8K/blob/main/requirements.txt) is my spaces repo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d0dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "\n",
    "import gradio\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.all import *\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import specgram\n",
    "import librosa\n",
    "import librosa.display\n",
    "from huggingface_hub import hf_hub_download\n",
    "from fastai.learner import load_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9aa4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71c862ec8aa423d8d046c295ff32a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f95c436434485b871e3c4b6139516d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/87.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "\n",
    "ref_file = hf_hub_download(\"gputrain/UrbanSound8K-model\", \"UrbanSound8K.csv\")\n",
    "\n",
    "model_file = hf_hub_download(\"gputrain/UrbanSound8K-model\", \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f37c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
