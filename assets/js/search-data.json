{
  
    
        "post0": {
            "title": "Urban Sounds 8k Classification with Hugging Face Demo",
            "content": "Hugging Face Demo . Here is a demo of what this model at Hugging Face : Urban Sound 8K Classification . Background . Urban Sounds is a dataset of 8732 labeled sounds of less than 4 seconds each from 10 classes. Dataset for UrbanSounds8K contains these 10 classes: . air_conditioner | car_horn | children_playing | dog_bark | drilling | engine_idling | gun_shot | jackhammer | siren | street_music | Research with this dataset as of 2019 and optimized ML approaches as of late 2019 had classification accuracy at 74% with a k-nearest neighbours (KNN) algorithm. A deep learning neural network trained from scratch obtained accuracy at 76% accuracy. . . (accuracy metrics for research article) . The state-of-the-art methods for audio classification approach this problem as an image classification task. For such image classification problems from audio samples, three common transformation approaches are: . Linear Spectrograms | | Log Spectrograms | | Mel Spectrograms | | . You can learn more about these three transformations in Scott Duda&#39;s article and Ketan Doshi&#39;s writing, reasoning why Mel Spectrograms perform better in general for visual transformations of audio files. . The transformation on these audio files is another notebook that I will add a write-up here. You can find all of the associated code here. . Code . Import the necessary modules . Using an AWS conda_pytorch_p38 environment with a ml.g4dn.2xlarge machine type . # !pip install librosa # !pip install fastbook # !pip install gradio . . import pandas as pd from fastai.vision.all import * from fastai.data.all import * import matplotlib.pyplot as plt from matplotlib.pyplot import specgram import librosa import librosa.display import numpy as np from pathlib import Path import os import random import IPython from tqdm import tqdm from sklearn.metrics import accuracy_score import gradio as gr from collections import OrderedDict . . Custom Labelling Function For Classification . This function reads the categorisation information into a dictionary and then uses that filename lookup to recognise the class of a particular image . df = pd.read_csv(&#39;UrbanSound8K/metadata/UrbanSound8K.csv&#39;) #classification information across folds as provided from Urbansounds df[&#39;fname&#39;] = df[[&#39;slice_file_name&#39;,&#39;fold&#39;]].apply (lambda x: str(x[&#39;slice_file_name&#39;][:-4])+&#39;.png&#39;.strip(),axis=1 ) my_dict = dict(zip(df.fname,df[&#39;class&#39;])) def label_func(f_name): f_name = str(f_name).split(&#39;/&#39;)[-1:][0] return my_dict[f_name] . . File distribution across the folds . df.groupby([&#39;fold&#39;]).classID.count().sort_values(ascending=False).plot.bar() plt.ylabel(&#39;Files in each fold&#39;) plt.title(&#39;Files in each fold&#39;) . . Text(0.5, 1.0, &#39;Files in each fold&#39;) . Class distribution across the sound types . df.groupby(&#39;class&#39;).classID.count().sort_values(ascending=False).plot.bar() plt.ylabel(&#39;count&#39;) plt.title(&#39;Class distribution in the dataset&#39;) . . Text(0.5, 1.0, &#39;Class distribution in the dataset&#39;) . Model Build . Spider through all the folders for images (transformation of sound to melspectrograms is another notebook). . all_folds = list(np.arange(1,11)) all_folders = [str(i) for i in all_folds] image_files_loc = &#39;UrbanSoundTransforms/mel_spectrogram/&#39; all_files = get_image_files(image_files_loc,recurse=True, folders =all_folders ) . . Datablock with an 80-20 Random split on entire dataset . dblock = DataBlock(blocks=(ImageBlock,CategoryBlock), get_y = label_func, splitter = RandomSplitter(seed=1), ) dl = dblock.dataloaders(all_files) print (&#39;Train has {0} images and test has {1} images.&#39; .format(len(dl.train_ds),len(dl.valid_ds))) learn = vision_learner(dl, resnet34, metrics=accuracy) learn.fine_tune(3) . . Train has 6986 images and test has 1746 images. . epoch train_loss valid_loss accuracy time . 0 | 1.510322 | 0.698512 | 0.781787 | 00:31 | . epoch train_loss valid_loss accuracy time . 0 | 0.615340 | 0.356023 | 0.888889 | 00:39 | . 1 | 0.270150 | 0.213896 | 0.932990 | 00:40 | . 2 | 0.084770 | 0.181070 | 0.943299 | 00:40 | . Export the model . learn.export() . .",
            "url": "https://www.gputrain.com/sound/hugging%20face/fastai/2022/05/23/Urban-Sounds-8k-Classification-with-Hugging-Face-Demo.html",
            "relUrl": "/sound/hugging%20face/fastai/2022/05/23/Urban-Sounds-8k-Classification-with-Hugging-Face-Demo.html",
            "date": " • May 23, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Deploying a Fast AI model to Hugging Face",
            "content": "Know before getting started . This notebook code is the same used to create my app.py file you can find in UrbanSounds8k spaces repo. . Creating a space is simple and intuitive at Hugging Face. You will need a &quot;Create a new space&quot; and &quot;Create a new model repository&quot; at huggingfaces. You will find the interface to create a new model repository (repo) in your profile settings. . ![](blogimg/createmodel.PNG) . /bin/bash: -c: line 0: syntax error near unexpected token `blogimg/createmodel.PNG&#39; /bin/bash: -c: line 0: `[](blogimg/createmodel.PNG)&#39; . If you upload your model artifacts into your spaces repository, you will run into 404 or 403 series errors. Once you create a model repo, the installation steps of Hugging Face will have an install git lfs in the set of instructions specific to the location you clone this empty repo. . If you upload your model artifacts into your spaces repository, you will run into 404 or 403 series errors. Once you create a model repo, the installation steps of Hugging Face will have an install git lfs in the set of instructions specific to the location you clone this empty repo. . Add in that repo before copying your model the *.pkl file from the earlier step; ensure you track pkl files as a type of file managed by Git LFS . git lfs track &quot;*.pkl&quot; . Tip: Note what is my spaces repo and what is in my model repo . If you miss this step you will run into 403 errors as you execute this line: . model_file = hf_hub_download(&quot;gputrain/UrbanSound8K-model&quot;, &quot;model.pkl&quot;) . Back to spaces repo, for which I have specific requirements.txt to be able to load librosa modules to get my inference function to work. In my example, I also needed to get my labeller function to get my model to work. This requirements.txt is my spaces repo. .",
            "url": "https://www.gputrain.com/sound/hugging%20face/fastai/2021/01/20/temp.html",
            "relUrl": "/sound/hugging%20face/fastai/2021/01/20/temp.html",
            "date": " • Jan 20, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Joe",
          "content": "Hello there. I am Joseph Matthew. . Welcome to my space, where I share some Jupyter notebook based experiments in my self-directed learning journey around machine learning and data wrangling. I enjoy developing solutions to real-world problems that leverage massive parallel architectures like the cloud, Apache Spark, and GPUs. . You can reach me on Twitter - @gputrain or LinkedIn. .",
          "url": "https://www.gputrain.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://www.gputrain.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}